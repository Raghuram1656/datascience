{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pet_Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raghuram1656/datascience/blob/master/Pet_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "VmZkpVSvhZ0B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **PET CLASSIFICATION USING TENSORFLOW  /    KERAS**"
      ]
    },
    {
      "metadata": {
        "id": "93CFkDlr5VoP",
        "colab_type": "code",
        "outputId": "e8f47849-0f08-4035-ba6f-183e6bd01b75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "look at the below code\n",
        "i have mounted it from my gdrive direct"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
           
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iA-zGx5_hEQV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf    \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "#from PIL import Image\n",
        "import PIL.Image as Image\n",
        "\n",
        "import cv2\n",
        "\n",
        "from __future__ import print_function\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pdfw8gb5hhvj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers  import Dense,Dropout,Conv2D,MaxPooling2D,Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.activations import relu,softmax\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "import tensorflow.contrib.keras as keras\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fK8VHK2a2zOA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility \n",
        "seed = 7 \n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hWh7c0Od52IP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For CNN, your input must be a 4-D tensor [batch_size, width, height, channels].Also for training all images must be of the same size - WIDTH and HEIGHT.\n"
      ]
    },
    {
      "metadata": {
        "id": "6jP5JsWf4G-j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dir = '/content/gdrive/My Drive/Projects/train/Images'\n",
        "train_images = []\n",
        "train_labels = []\n",
        "train_data = []\n",
        "\n",
        "\n",
        "\n",
        "test_dir  = '/content/gdrive/My Drive/Projects/test/Images'\n",
        "test_images = []\n",
        "test_labels = []\n",
        "test_data = []\n",
        "\n",
        "\n",
        "side = 32\n",
        "channels   = 3\n",
        "batch_size = 100\n",
        "\n",
        "img_size = 32\n",
        "num_channels = 3\n",
        "img_size_flat = img_size * img_size * num_channels\n",
        "img_shape = (img_size, img_size)\n",
        "fc_size=32 #size of the output of final FC layer\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BBNYfk5EB2uD",
        "colab_type": "code",
        "outputId": "3069576f-f251-480f-c528-b83d63c55255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "cell_type": "code",
      "source": [
        "os.listdir(train_dir)"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1_cat.jpg',\n",
              " '3_cat.jpg',\n",
              " '1_dog.jpg',\n",
              " '2_dog.jpg',\n",
              " '2_cat.jpg',\n",
              " '5_cat.jpg',\n",
              " '4_dog.jpg',\n",
              " '4_cat.jpg',\n",
              " '5_dog.jpg',\n",
              " '3_dog.jpg',\n",
              " '6_cat.jpg',\n",
              " '7_cat.jpg',\n",
              " '6_dog.jpg',\n",
              " '7_dog.jpg',\n",
              " '10_cat.jpg',\n",
              " '9_dog.jpg',\n",
              " '9_cat.jpg',\n",
              " '10_dog.jpg',\n",
              " '8_dog.jpg',\n",
              " '8_cat.jpg',\n",
              " '11_cat.jpg',\n",
              " '12_dog.jpg',\n",
              " '11_dog.jpg',\n",
              " '12_cat.jpg',\n",
              " '14_cat.jpg',\n",
              " '13_dog.jpg',\n",
              " '15_cat.jpg',\n",
              " '15_dog.jpg',\n",
              " '13_cat.jpg',\n",
              " '14_dog.jpg',\n",
              " '16_cat.jpg',\n",
              " '16_dog.jpg',\n",
              " '17_cat.jpg',\n",
              " '17_dog.jpg',\n",
              " '20_cat.jpg',\n",
              " '19_dog.jpg',\n",
              " '18_dog.jpg',\n",
              " '20_dog.jpg',\n",
              " '18_cat.jpg',\n",
              " '19_cat.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 291
        }
      ]
    },
    {
      "metadata": {
        "id": "6o-wzy__nbFW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4097
        },
        "outputId": "228cb70f-9a92-482f-e22c-39943efb7c03"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Train images and labels processing\n",
        "\n",
        "for file_name in os.listdir(train_dir):\n",
        "    #img = mpimg.imread(os.path.join(train_dir, file_name))\n",
        "    #plt.imshow(img)\n",
        "    img = Image.open(os.path.join(train_dir, file_name))\n",
        "    #img.show()\n",
        "    \n",
        "    \n",
        "    print('before resize')\n",
        "    print(img.width)\n",
        "    print(img.height)\n",
        "    \n",
        "    # resize the image read\n",
        "    img = img.resize((side,side), Image.ANTIALIAS) # resize images \n",
        "    #plt.imshow(img)\n",
        "    #img.show()\n",
        "    print('after resize')\n",
        "    #width,height = img.size\n",
        "    print(img.width)\n",
        "    print(img.height)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    # Reading as an Array to represent Neural Networks\n",
        "    \n",
        "    train_images.append(np.asarray(img))  # read image as np array into train_images\n",
        "#     train_images.append(img)  # read image as np array into train_images\n",
        "    \n",
        "    # Train Labels \n",
        "    \n",
        "    if file_name.endswith(\".jpg\"):\n",
        "        temp_label = file_name.split('.jpg')\n",
        "        temp_file_name = str(temp_label[0])\n",
        "        \n",
        "    if len(temp_file_name) > 0:\n",
        "            temp_label_2 = temp_file_name.split('_')\n",
        "            if 'dog' in temp_label_2:\n",
        "                train_labels.append([0,1])\n",
        "            elif 'cat' in temp_label_2:\n",
        "                train_labels.append([1,0])\n",
        "                \n",
        "   "
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before resize\n",
            "300\n",
            "281\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "415\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "327\n",
            "500\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "188\n",
            "199\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "312\n",
            "397\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "176\n",
            "144\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "300\n",
            "288\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "375\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "376\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "375\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "400\n",
            "304\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "495\n",
            "500\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "488\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "300\n",
            "264\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "489\n",
            "500\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "369\n",
            "500\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "320\n",
            "426\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "269\n",
            "293\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "470\n",
            "500\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "461\n",
            "346\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "432\n",
            "410\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "98\n",
            "162\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "135\n",
            "102\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "300\n",
            "225\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "320\n",
            "268\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "363\n",
            "428\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "406\n",
            "353\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "375\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "315\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "387\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "448\n",
            "259\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "381\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "375\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "272\n",
            "336\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "375\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "300\n",
            "225\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "216\n",
            "348\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "333\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "375\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "320\n",
            "224\n",
            "after resize\n",
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FnVX4Ry_nwJ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2057
        },
        "outputId": "915b5c33-0933-48aa-dc35-1e5ef2cca0d1"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# test images and labels processing\n",
        "\n",
        "for file_name in os.listdir(test_dir):\n",
        "    #img = mpimg.imread(os.path.join(train_dir, file_name))\n",
        "    #plt.imshow(img)\n",
        "    img = Image.open(os.path.join(test_dir, file_name))\n",
        "    #img.show()\n",
        "    \n",
        "    \n",
        "    print('before resize')\n",
        "    print(img.width)\n",
        "    print(img.height)\n",
        "    #\n",
        "    img = img.resize((side,side), Image.ANTIALIAS) # resize images \n",
        "    #plt.imshow(img)\n",
        "    #img.show()\n",
        "    print('after resize')\n",
        "    #width,height = img.size\n",
        "    print(img.width)\n",
        "    print(img.height)\n",
        "    \n",
        "    \n",
        "    test_images.append(np.asarray(img))  # read image as np array into test_images\n",
        "#     test_images.append(img)  # read image as np array into test_images\n",
        "    \n",
        "    # test labels\n",
        "    if file_name.endswith(\".jpg\"):\n",
        "        temp_label = file_name.split('.jpg')\n",
        "        temp_file_name = str(temp_label[0])\n",
        "        \n",
        "    if len(temp_file_name) > 0:\n",
        "            temp_label_2 = temp_file_name.split('_')\n",
        "            if 'dog' in temp_label_2:\n",
        "                test_labels.append([0,1])\n",
        "            elif 'cat' in temp_label_2:\n",
        "                test_labels.append([1,0])"
      ],
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before resize\n",
            "297\n",
            "200\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "350\n",
            "343\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "387\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "253\n",
            "400\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "215\n",
            "175\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "400\n",
            "375\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "350\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "332\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "375\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "375\n",
            "500\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "441\n",
            "500\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "373\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "375\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "433\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "170\n",
            "222\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "375\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "458\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "260\n",
            "480\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "440\n",
            "268\n",
            "after resize\n",
            "32\n",
            "32\n",
            "before resize\n",
            "500\n",
            "375\n",
            "after resize\n",
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uYH-Rm6y0ewJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "29dfe5c8-e073-4f4f-9d78-91fe658881a0"
      },
      "cell_type": "code",
      "source": [
        "X_train = np.asarray(train_images) # i have already converted as array in the above lines of code\n",
        "y_train = np.array(train_labels)\n",
        "\n",
        "X_test  = np.asarray(test_images) # i have already converted as array in the above lines of code\n",
        "y_test  = np.array(test_labels)\n",
        "\n",
        "\n",
        "print('length of train image set',len(X_train))\n",
        "print('X_data shape:', X_train[0].shape)\n",
        "print('y_data shape:', y_train.shape)\n"
      ],
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of train image set 40\n",
            "X_data shape: (32, 32, 3)\n",
            "y_data shape: (40, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2xZck_vjqxUv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There are some steps to be performed berfoe CNN\n",
        "1. Standardize the images like / = 255\n",
        "2. split into train and test validators\n",
        "3. build cnn model\n"
      ]
    },
    {
      "metadata": {
        "id": "eY-40AU_qvDs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "\n",
        "# Initialising the CNN\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "input_shape1 = (32,32,3)\n",
        "# taking -1 because in the run time the dynamic optimum value will be considered\n",
        "\n",
        "\n",
        "# conv layer 1 with 32 filters of kernel  size[5,5]\n",
        "model.add(Conv2D(32, (5, 5), input_shape = input_shape1,  padding=\"valid\",activation = 'relu'))\n",
        "\n",
        "# pooling layer 1 with pool size[2,2] and stride 2\n",
        "model.add(MaxPooling2D(pool_size = (2, 2), strides=2))\n",
        "\n",
        "# conv layer 2 with 64 filters of kernel  size[5,5]\n",
        "model.add(Conv2D(64, (5, 5),  padding=\"valid\",activation = 'relu'))\n",
        "\n",
        "\n",
        "# pooling layer 2 with pool size[2,2] and stride 2\n",
        "model.add(MaxPooling2D(pool_size = (2, 2), strides=2))\n",
        "\n",
        "\n",
        "# Flattening\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "\n",
        "# dense layer whose output size is fixed in the hyper parameter: fc_size=32\n",
        "model.add(Dense(units = 1024,activation = 'softmax'))\n",
        "\n",
        "\n",
        "#Drop out probability 0.4\n",
        "model.add(Dropout(0.20))\n",
        "\n",
        "\n",
        "# 4 Output Layer\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "\n",
        "epochs_V = 1000 \n",
        "learning_rate_V = 0.001 \n",
        "decay_rate = learning_rate_V / epochs_V \n",
        "momentum_V = 0.8 \n",
        "\n",
        "\n",
        "#Optimizer Definiton\n",
        "optimizer_function = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay_rate, amsgrad=False)\n",
        "\n",
        "\n",
        "# Compiling the CNN\n",
        "model.compile(optimizer = optimizer_function, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K3xEtlUNGB2q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Standardization Process : Actually we standardize using the max dimension for each image. Here i used a different approach by taking the highest 255.\n",
        "\n",
        "\n",
        "X_train = np.array((X_train/255.0),dtype=np.float32)\n",
        "X_test = np.array((X_test/255.0), dtype=np.float32)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_soG46_VS6GZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10234
        },
        "outputId": "ebbaee6d-22d1-4536-f06c-32bf47f8d737"
      },
      "cell_type": "code",
      "source": [
        "# Train Model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test,y_test),shuffle=True,epochs=300, batch_size=64,verbose=1)\n"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40 samples, validate on 20 samples\n",
            "Epoch 1/300\n",
            "40/40 [==============================] - 0s 9ms/sample - loss: 0.6932 - acc: 0.4750 - val_loss: 0.6932 - val_acc: 0.5000\n",
            "Epoch 2/300\n",
            "40/40 [==============================] - 0s 401us/sample - loss: 0.6931 - acc: 0.5250 - val_loss: 0.6932 - val_acc: 0.5000\n",
            "Epoch 3/300\n",
            "40/40 [==============================] - 0s 437us/sample - loss: 0.6930 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5000\n",
            "Epoch 4/300\n",
            "40/40 [==============================] - 0s 399us/sample - loss: 0.6929 - acc: 0.7250 - val_loss: 0.6932 - val_acc: 0.5000\n",
            "Epoch 5/300\n",
            "40/40 [==============================] - 0s 401us/sample - loss: 0.6932 - acc: 0.4500 - val_loss: 0.6932 - val_acc: 0.5000\n",
            "Epoch 6/300\n",
            "40/40 [==============================] - 0s 402us/sample - loss: 0.6931 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5500\n",
            "Epoch 7/300\n",
            "40/40 [==============================] - 0s 405us/sample - loss: 0.6930 - acc: 0.6250 - val_loss: 0.6932 - val_acc: 0.4500\n",
            "Epoch 8/300\n",
            "40/40 [==============================] - 0s 408us/sample - loss: 0.6931 - acc: 0.6250 - val_loss: 0.6932 - val_acc: 0.4000\n",
            "Epoch 9/300\n",
            "40/40 [==============================] - 0s 592us/sample - loss: 0.6929 - acc: 0.6000 - val_loss: 0.6932 - val_acc: 0.4000\n",
            "Epoch 10/300\n",
            "40/40 [==============================] - 0s 432us/sample - loss: 0.6927 - acc: 0.6750 - val_loss: 0.6932 - val_acc: 0.5000\n",
            "Epoch 11/300\n",
            "40/40 [==============================] - 0s 500us/sample - loss: 0.6927 - acc: 0.6500 - val_loss: 0.6933 - val_acc: 0.4000\n",
            "Epoch 12/300\n",
            "40/40 [==============================] - 0s 469us/sample - loss: 0.6926 - acc: 0.6000 - val_loss: 0.6933 - val_acc: 0.4000\n",
            "Epoch 13/300\n",
            "40/40 [==============================] - 0s 398us/sample - loss: 0.6922 - acc: 0.7500 - val_loss: 0.6935 - val_acc: 0.5000\n",
            "Epoch 14/300\n",
            "40/40 [==============================] - 0s 404us/sample - loss: 0.6920 - acc: 0.7500 - val_loss: 0.6937 - val_acc: 0.4500\n",
            "Epoch 15/300\n",
            "40/40 [==============================] - 0s 471us/sample - loss: 0.6915 - acc: 0.6250 - val_loss: 0.6939 - val_acc: 0.4500\n",
            "Epoch 16/300\n",
            "40/40 [==============================] - 0s 404us/sample - loss: 0.6900 - acc: 0.6750 - val_loss: 0.6936 - val_acc: 0.4000\n",
            "Epoch 17/300\n",
            "40/40 [==============================] - 0s 428us/sample - loss: 0.6890 - acc: 0.7250 - val_loss: 0.6949 - val_acc: 0.5000\n",
            "Epoch 18/300\n",
            "40/40 [==============================] - 0s 415us/sample - loss: 0.6893 - acc: 0.5750 - val_loss: 0.6931 - val_acc: 0.6000\n",
            "Epoch 19/300\n",
            "40/40 [==============================] - 0s 435us/sample - loss: 0.6847 - acc: 0.6500 - val_loss: 0.6931 - val_acc: 0.4500\n",
            "Epoch 20/300\n",
            "40/40 [==============================] - 0s 425us/sample - loss: 0.6820 - acc: 0.6250 - val_loss: 0.6930 - val_acc: 0.5500\n",
            "Epoch 21/300\n",
            "40/40 [==============================] - 0s 423us/sample - loss: 0.6767 - acc: 0.6750 - val_loss: 0.6947 - val_acc: 0.5500\n",
            "Epoch 22/300\n",
            "40/40 [==============================] - 0s 495us/sample - loss: 0.6759 - acc: 0.7000 - val_loss: 0.6916 - val_acc: 0.4500\n",
            "Epoch 23/300\n",
            "40/40 [==============================] - 0s 595us/sample - loss: 0.6707 - acc: 0.6500 - val_loss: 0.6905 - val_acc: 0.6000\n",
            "Epoch 24/300\n",
            "40/40 [==============================] - 0s 546us/sample - loss: 0.6759 - acc: 0.6250 - val_loss: 0.6915 - val_acc: 0.4500\n",
            "Epoch 25/300\n",
            "40/40 [==============================] - 0s 492us/sample - loss: 0.6642 - acc: 0.7250 - val_loss: 0.6929 - val_acc: 0.4500\n",
            "Epoch 26/300\n",
            "40/40 [==============================] - 0s 525us/sample - loss: 0.6625 - acc: 0.7250 - val_loss: 0.6923 - val_acc: 0.4500\n",
            "Epoch 27/300\n",
            "40/40 [==============================] - 0s 438us/sample - loss: 0.6614 - acc: 0.7000 - val_loss: 0.6890 - val_acc: 0.6000\n",
            "Epoch 28/300\n",
            "40/40 [==============================] - 0s 409us/sample - loss: 0.6622 - acc: 0.7750 - val_loss: 0.6869 - val_acc: 0.5500\n",
            "Epoch 29/300\n",
            "40/40 [==============================] - 0s 412us/sample - loss: 0.6594 - acc: 0.7250 - val_loss: 0.6869 - val_acc: 0.5000\n",
            "Epoch 30/300\n",
            "40/40 [==============================] - 0s 402us/sample - loss: 0.6474 - acc: 0.8000 - val_loss: 0.6876 - val_acc: 0.5500\n",
            "Epoch 31/300\n",
            "40/40 [==============================] - 0s 473us/sample - loss: 0.6739 - acc: 0.5750 - val_loss: 0.6833 - val_acc: 0.5500\n",
            "Epoch 32/300\n",
            "40/40 [==============================] - 0s 453us/sample - loss: 0.6475 - acc: 0.7750 - val_loss: 0.6827 - val_acc: 0.6000\n",
            "Epoch 33/300\n",
            "40/40 [==============================] - 0s 485us/sample - loss: 0.6527 - acc: 0.7250 - val_loss: 0.6891 - val_acc: 0.5500\n",
            "Epoch 34/300\n",
            "40/40 [==============================] - 0s 445us/sample - loss: 0.6475 - acc: 0.7500 - val_loss: 0.6917 - val_acc: 0.4500\n",
            "Epoch 35/300\n",
            "40/40 [==============================] - 0s 492us/sample - loss: 0.6517 - acc: 0.7000 - val_loss: 0.6848 - val_acc: 0.6000\n",
            "Epoch 36/300\n",
            "40/40 [==============================] - 0s 476us/sample - loss: 0.6540 - acc: 0.7000 - val_loss: 0.6917 - val_acc: 0.5000\n",
            "Epoch 37/300\n",
            "40/40 [==============================] - 0s 421us/sample - loss: 0.6445 - acc: 0.7500 - val_loss: 0.6962 - val_acc: 0.4000\n",
            "Epoch 38/300\n",
            "40/40 [==============================] - 0s 476us/sample - loss: 0.6511 - acc: 0.7250 - val_loss: 0.6971 - val_acc: 0.4500\n",
            "Epoch 39/300\n",
            "40/40 [==============================] - 0s 457us/sample - loss: 0.6330 - acc: 0.8250 - val_loss: 0.6911 - val_acc: 0.5000\n",
            "Epoch 40/300\n",
            "40/40 [==============================] - 0s 444us/sample - loss: 0.6398 - acc: 0.7500 - val_loss: 0.6939 - val_acc: 0.4500\n",
            "Epoch 41/300\n",
            "40/40 [==============================] - 0s 462us/sample - loss: 0.6285 - acc: 0.8250 - val_loss: 0.6939 - val_acc: 0.4500\n",
            "Epoch 42/300\n",
            "40/40 [==============================] - 0s 510us/sample - loss: 0.6208 - acc: 0.8750 - val_loss: 0.6941 - val_acc: 0.5000\n",
            "Epoch 43/300\n",
            "40/40 [==============================] - 0s 442us/sample - loss: 0.6341 - acc: 0.7250 - val_loss: 0.6877 - val_acc: 0.5500\n",
            "Epoch 44/300\n",
            "40/40 [==============================] - 0s 429us/sample - loss: 0.6400 - acc: 0.7500 - val_loss: 0.6929 - val_acc: 0.4500\n",
            "Epoch 45/300\n",
            "40/40 [==============================] - 0s 421us/sample - loss: 0.6348 - acc: 0.7500 - val_loss: 0.6973 - val_acc: 0.4500\n",
            "Epoch 46/300\n",
            "40/40 [==============================] - 0s 471us/sample - loss: 0.6316 - acc: 0.7750 - val_loss: 0.6985 - val_acc: 0.4500\n",
            "Epoch 47/300\n",
            "40/40 [==============================] - 0s 443us/sample - loss: 0.6254 - acc: 0.8000 - val_loss: 0.6917 - val_acc: 0.4500\n",
            "Epoch 48/300\n",
            "40/40 [==============================] - 0s 477us/sample - loss: 0.6148 - acc: 0.8500 - val_loss: 0.7015 - val_acc: 0.4000\n",
            "Epoch 49/300\n",
            "40/40 [==============================] - 0s 398us/sample - loss: 0.6185 - acc: 0.8250 - val_loss: 0.7033 - val_acc: 0.4500\n",
            "Epoch 50/300\n",
            "40/40 [==============================] - 0s 476us/sample - loss: 0.6133 - acc: 0.8250 - val_loss: 0.6978 - val_acc: 0.4000\n",
            "Epoch 51/300\n",
            "40/40 [==============================] - 0s 456us/sample - loss: 0.6130 - acc: 0.7500 - val_loss: 0.6963 - val_acc: 0.4000\n",
            "Epoch 52/300\n",
            "40/40 [==============================] - 0s 452us/sample - loss: 0.5961 - acc: 0.9000 - val_loss: 0.7069 - val_acc: 0.4500\n",
            "Epoch 53/300\n",
            "40/40 [==============================] - 0s 466us/sample - loss: 0.6116 - acc: 0.8500 - val_loss: 0.7024 - val_acc: 0.4000\n",
            "Epoch 54/300\n",
            "40/40 [==============================] - 0s 479us/sample - loss: 0.6098 - acc: 0.8250 - val_loss: 0.7011 - val_acc: 0.4000\n",
            "Epoch 55/300\n",
            "40/40 [==============================] - 0s 523us/sample - loss: 0.6067 - acc: 0.8250 - val_loss: 0.7104 - val_acc: 0.4000\n",
            "Epoch 56/300\n",
            "40/40 [==============================] - 0s 430us/sample - loss: 0.6117 - acc: 0.8500 - val_loss: 0.7078 - val_acc: 0.4000\n",
            "Epoch 57/300\n",
            "40/40 [==============================] - 0s 428us/sample - loss: 0.5927 - acc: 0.8500 - val_loss: 0.7126 - val_acc: 0.3500\n",
            "Epoch 58/300\n",
            "40/40 [==============================] - 0s 478us/sample - loss: 0.5905 - acc: 0.9250 - val_loss: 0.7101 - val_acc: 0.4000\n",
            "Epoch 59/300\n",
            "40/40 [==============================] - 0s 500us/sample - loss: 0.5961 - acc: 0.8500 - val_loss: 0.7015 - val_acc: 0.4500\n",
            "Epoch 60/300\n",
            "40/40 [==============================] - 0s 473us/sample - loss: 0.5875 - acc: 0.8750 - val_loss: 0.6906 - val_acc: 0.5500\n",
            "Epoch 61/300\n",
            "40/40 [==============================] - 0s 477us/sample - loss: 0.5804 - acc: 0.9250 - val_loss: 0.6997 - val_acc: 0.4500\n",
            "Epoch 62/300\n",
            "40/40 [==============================] - 0s 460us/sample - loss: 0.6107 - acc: 0.7500 - val_loss: 0.7012 - val_acc: 0.4500\n",
            "Epoch 63/300\n",
            "40/40 [==============================] - 0s 492us/sample - loss: 0.5832 - acc: 0.9250 - val_loss: 0.6958 - val_acc: 0.5000\n",
            "Epoch 64/300\n",
            "40/40 [==============================] - 0s 477us/sample - loss: 0.5907 - acc: 0.8500 - val_loss: 0.6932 - val_acc: 0.5000\n",
            "Epoch 65/300\n",
            "40/40 [==============================] - 0s 623us/sample - loss: 0.5878 - acc: 0.8750 - val_loss: 0.6994 - val_acc: 0.4500\n",
            "Epoch 66/300\n",
            "40/40 [==============================] - 0s 484us/sample - loss: 0.5794 - acc: 0.8500 - val_loss: 0.6988 - val_acc: 0.4500\n",
            "Epoch 67/300\n",
            "40/40 [==============================] - 0s 404us/sample - loss: 0.5887 - acc: 0.8250 - val_loss: 0.6936 - val_acc: 0.5500\n",
            "Epoch 68/300\n",
            "40/40 [==============================] - 0s 444us/sample - loss: 0.5875 - acc: 0.8500 - val_loss: 0.6942 - val_acc: 0.5500\n",
            "Epoch 69/300\n",
            "40/40 [==============================] - 0s 464us/sample - loss: 0.5807 - acc: 0.9250 - val_loss: 0.6979 - val_acc: 0.4500\n",
            "Epoch 70/300\n",
            "40/40 [==============================] - 0s 478us/sample - loss: 0.5735 - acc: 0.8000 - val_loss: 0.6978 - val_acc: 0.5000\n",
            "Epoch 71/300\n",
            "40/40 [==============================] - 0s 498us/sample - loss: 0.5621 - acc: 0.9250 - val_loss: 0.6970 - val_acc: 0.5000\n",
            "Epoch 72/300\n",
            "40/40 [==============================] - 0s 487us/sample - loss: 0.5941 - acc: 0.8250 - val_loss: 0.6956 - val_acc: 0.5500\n",
            "Epoch 73/300\n",
            "40/40 [==============================] - 0s 399us/sample - loss: 0.5896 - acc: 0.7750 - val_loss: 0.6955 - val_acc: 0.5500\n",
            "Epoch 74/300\n",
            "40/40 [==============================] - 0s 457us/sample - loss: 0.5583 - acc: 0.9000 - val_loss: 0.6972 - val_acc: 0.5000\n",
            "Epoch 75/300\n",
            "40/40 [==============================] - 0s 478us/sample - loss: 0.5648 - acc: 0.8750 - val_loss: 0.6966 - val_acc: 0.4500\n",
            "Epoch 76/300\n",
            "40/40 [==============================] - 0s 431us/sample - loss: 0.5755 - acc: 0.8250 - val_loss: 0.6957 - val_acc: 0.4500\n",
            "Epoch 77/300\n",
            "40/40 [==============================] - 0s 553us/sample - loss: 0.5768 - acc: 0.9000 - val_loss: 0.6941 - val_acc: 0.4500\n",
            "Epoch 78/300\n",
            "40/40 [==============================] - 0s 473us/sample - loss: 0.5589 - acc: 0.9000 - val_loss: 0.6924 - val_acc: 0.5500\n",
            "Epoch 79/300\n",
            "40/40 [==============================] - 0s 492us/sample - loss: 0.5752 - acc: 0.8250 - val_loss: 0.6889 - val_acc: 0.5500\n",
            "Epoch 80/300\n",
            "40/40 [==============================] - 0s 457us/sample - loss: 0.5587 - acc: 0.9250 - val_loss: 0.6857 - val_acc: 0.5500\n",
            "Epoch 81/300\n",
            "40/40 [==============================] - 0s 398us/sample - loss: 0.5697 - acc: 0.8000 - val_loss: 0.6822 - val_acc: 0.5500\n",
            "Epoch 82/300\n",
            "40/40 [==============================] - 0s 468us/sample - loss: 0.5725 - acc: 0.8500 - val_loss: 0.6825 - val_acc: 0.5500\n",
            "Epoch 83/300\n",
            "40/40 [==============================] - 0s 491us/sample - loss: 0.5775 - acc: 0.8500 - val_loss: 0.6798 - val_acc: 0.5500\n",
            "Epoch 84/300\n",
            "40/40 [==============================] - 0s 455us/sample - loss: 0.5578 - acc: 0.8750 - val_loss: 0.6789 - val_acc: 0.5500\n",
            "Epoch 85/300\n",
            "40/40 [==============================] - 0s 390us/sample - loss: 0.5511 - acc: 0.8750 - val_loss: 0.6752 - val_acc: 0.6000\n",
            "Epoch 86/300\n",
            "40/40 [==============================] - 0s 437us/sample - loss: 0.5640 - acc: 0.8750 - val_loss: 0.6792 - val_acc: 0.5500\n",
            "Epoch 87/300\n",
            "40/40 [==============================] - 0s 493us/sample - loss: 0.5800 - acc: 0.8250 - val_loss: 0.6773 - val_acc: 0.5500\n",
            "Epoch 88/300\n",
            "40/40 [==============================] - 0s 440us/sample - loss: 0.5519 - acc: 0.8750 - val_loss: 0.6791 - val_acc: 0.5500\n",
            "Epoch 89/300\n",
            "40/40 [==============================] - 0s 461us/sample - loss: 0.5457 - acc: 0.8750 - val_loss: 0.6787 - val_acc: 0.5500\n",
            "Epoch 90/300\n",
            "40/40 [==============================] - 0s 409us/sample - loss: 0.5444 - acc: 0.9000 - val_loss: 0.6791 - val_acc: 0.5500\n",
            "Epoch 91/300\n",
            "40/40 [==============================] - 0s 450us/sample - loss: 0.5574 - acc: 0.8750 - val_loss: 0.6813 - val_acc: 0.5500\n",
            "Epoch 92/300\n",
            "40/40 [==============================] - 0s 440us/sample - loss: 0.5590 - acc: 0.8750 - val_loss: 0.6812 - val_acc: 0.5500\n",
            "Epoch 93/300\n",
            "40/40 [==============================] - 0s 430us/sample - loss: 0.5366 - acc: 0.8750 - val_loss: 0.6802 - val_acc: 0.5500\n",
            "Epoch 94/300\n",
            "40/40 [==============================] - 0s 516us/sample - loss: 0.5450 - acc: 0.8750 - val_loss: 0.6826 - val_acc: 0.5500\n",
            "Epoch 95/300\n",
            "40/40 [==============================] - 0s 446us/sample - loss: 0.5545 - acc: 0.8000 - val_loss: 0.6860 - val_acc: 0.5500\n",
            "Epoch 96/300\n",
            "40/40 [==============================] - 0s 409us/sample - loss: 0.5282 - acc: 0.9000 - val_loss: 0.6881 - val_acc: 0.5500\n",
            "Epoch 97/300\n",
            "40/40 [==============================] - 0s 462us/sample - loss: 0.5360 - acc: 0.9250 - val_loss: 0.6895 - val_acc: 0.5500\n",
            "Epoch 98/300\n",
            "40/40 [==============================] - 0s 411us/sample - loss: 0.5608 - acc: 0.8250 - val_loss: 0.6900 - val_acc: 0.5500\n",
            "Epoch 99/300\n",
            "40/40 [==============================] - 0s 430us/sample - loss: 0.5401 - acc: 0.8500 - val_loss: 0.6887 - val_acc: 0.5500\n",
            "Epoch 100/300\n",
            "40/40 [==============================] - 0s 410us/sample - loss: 0.5130 - acc: 0.9500 - val_loss: 0.6878 - val_acc: 0.5500\n",
            "Epoch 101/300\n",
            "40/40 [==============================] - 0s 403us/sample - loss: 0.5430 - acc: 0.8500 - val_loss: 0.6883 - val_acc: 0.5500\n",
            "Epoch 102/300\n",
            "40/40 [==============================] - 0s 405us/sample - loss: 0.5503 - acc: 0.8750 - val_loss: 0.6914 - val_acc: 0.5500\n",
            "Epoch 103/300\n",
            "40/40 [==============================] - 0s 440us/sample - loss: 0.5815 - acc: 0.8000 - val_loss: 0.6946 - val_acc: 0.5500\n",
            "Epoch 104/300\n",
            "40/40 [==============================] - 0s 444us/sample - loss: 0.5495 - acc: 0.8500 - val_loss: 0.6963 - val_acc: 0.5500\n",
            "Epoch 105/300\n",
            "40/40 [==============================] - 0s 420us/sample - loss: 0.5344 - acc: 0.8500 - val_loss: 0.6965 - val_acc: 0.5500\n",
            "Epoch 106/300\n",
            "40/40 [==============================] - 0s 420us/sample - loss: 0.5522 - acc: 0.8500 - val_loss: 0.6952 - val_acc: 0.5500\n",
            "Epoch 107/300\n",
            "40/40 [==============================] - 0s 601us/sample - loss: 0.5472 - acc: 0.8750 - val_loss: 0.6930 - val_acc: 0.5500\n",
            "Epoch 108/300\n",
            "40/40 [==============================] - 0s 554us/sample - loss: 0.5362 - acc: 0.8750 - val_loss: 0.6921 - val_acc: 0.5500\n",
            "Epoch 109/300\n",
            "40/40 [==============================] - 0s 452us/sample - loss: 0.5192 - acc: 0.8750 - val_loss: 0.6928 - val_acc: 0.5500\n",
            "Epoch 110/300\n",
            "40/40 [==============================] - 0s 477us/sample - loss: 0.5115 - acc: 0.9250 - val_loss: 0.6945 - val_acc: 0.5500\n",
            "Epoch 111/300\n",
            "40/40 [==============================] - 0s 412us/sample - loss: 0.5393 - acc: 0.8500 - val_loss: 0.6966 - val_acc: 0.5500\n",
            "Epoch 112/300\n",
            "40/40 [==============================] - 0s 453us/sample - loss: 0.5440 - acc: 0.8250 - val_loss: 0.6981 - val_acc: 0.5500\n",
            "Epoch 113/300\n",
            "40/40 [==============================] - 0s 497us/sample - loss: 0.5429 - acc: 0.8500 - val_loss: 0.6983 - val_acc: 0.5500\n",
            "Epoch 114/300\n",
            "40/40 [==============================] - 0s 480us/sample - loss: 0.5035 - acc: 0.9000 - val_loss: 0.6975 - val_acc: 0.5500\n",
            "Epoch 115/300\n",
            "40/40 [==============================] - 0s 480us/sample - loss: 0.5404 - acc: 0.8500 - val_loss: 0.6961 - val_acc: 0.5500\n",
            "Epoch 116/300\n",
            "40/40 [==============================] - 0s 457us/sample - loss: 0.5116 - acc: 0.9250 - val_loss: 0.6952 - val_acc: 0.5500\n",
            "Epoch 117/300\n",
            "40/40 [==============================] - 0s 474us/sample - loss: 0.5158 - acc: 0.9000 - val_loss: 0.6952 - val_acc: 0.5500\n",
            "Epoch 118/300\n",
            "40/40 [==============================] - 0s 538us/sample - loss: 0.5272 - acc: 0.9000 - val_loss: 0.6957 - val_acc: 0.5500\n",
            "Epoch 119/300\n",
            "40/40 [==============================] - 0s 518us/sample - loss: 0.5160 - acc: 0.8750 - val_loss: 0.6965 - val_acc: 0.5500\n",
            "Epoch 120/300\n",
            "40/40 [==============================] - 0s 472us/sample - loss: 0.5260 - acc: 0.8750 - val_loss: 0.6974 - val_acc: 0.5500\n",
            "Epoch 121/300\n",
            "40/40 [==============================] - 0s 490us/sample - loss: 0.5083 - acc: 0.9000 - val_loss: 0.6981 - val_acc: 0.5500\n",
            "Epoch 122/300\n",
            "40/40 [==============================] - 0s 472us/sample - loss: 0.5178 - acc: 0.9250 - val_loss: 0.6986 - val_acc: 0.5500\n",
            "Epoch 123/300\n",
            "40/40 [==============================] - 0s 450us/sample - loss: 0.5231 - acc: 0.9000 - val_loss: 0.6984 - val_acc: 0.5500\n",
            "Epoch 124/300\n",
            "40/40 [==============================] - 0s 382us/sample - loss: 0.5514 - acc: 0.8250 - val_loss: 0.6977 - val_acc: 0.5500\n",
            "Epoch 125/300\n",
            "40/40 [==============================] - 0s 464us/sample - loss: 0.4982 - acc: 0.9000 - val_loss: 0.6970 - val_acc: 0.5500\n",
            "Epoch 126/300\n",
            "40/40 [==============================] - 0s 403us/sample - loss: 0.5133 - acc: 0.9000 - val_loss: 0.6965 - val_acc: 0.5500\n",
            "Epoch 127/300\n",
            "40/40 [==============================] - 0s 492us/sample - loss: 0.5315 - acc: 0.8750 - val_loss: 0.6966 - val_acc: 0.5500\n",
            "Epoch 128/300\n",
            "40/40 [==============================] - 0s 450us/sample - loss: 0.5359 - acc: 0.9000 - val_loss: 0.6972 - val_acc: 0.5500\n",
            "Epoch 129/300\n",
            "40/40 [==============================] - 0s 401us/sample - loss: 0.5311 - acc: 0.8250 - val_loss: 0.6980 - val_acc: 0.5500\n",
            "Epoch 130/300\n",
            "40/40 [==============================] - 0s 472us/sample - loss: 0.5185 - acc: 0.8500 - val_loss: 0.6984 - val_acc: 0.5500\n",
            "Epoch 131/300\n",
            "40/40 [==============================] - 0s 423us/sample - loss: 0.4990 - acc: 0.9250 - val_loss: 0.6986 - val_acc: 0.5500\n",
            "Epoch 132/300\n",
            "40/40 [==============================] - 0s 455us/sample - loss: 0.5149 - acc: 0.9000 - val_loss: 0.6987 - val_acc: 0.5500\n",
            "Epoch 133/300\n",
            "40/40 [==============================] - 0s 388us/sample - loss: 0.5460 - acc: 0.8000 - val_loss: 0.6983 - val_acc: 0.5500\n",
            "Epoch 134/300\n",
            "40/40 [==============================] - 0s 466us/sample - loss: 0.5355 - acc: 0.7250 - val_loss: 0.6974 - val_acc: 0.5500\n",
            "Epoch 135/300\n",
            "40/40 [==============================] - 0s 389us/sample - loss: 0.5199 - acc: 0.8750 - val_loss: 0.6968 - val_acc: 0.5500\n",
            "Epoch 136/300\n",
            "40/40 [==============================] - 0s 465us/sample - loss: 0.4954 - acc: 0.9000 - val_loss: 0.6969 - val_acc: 0.5500\n",
            "Epoch 137/300\n",
            "40/40 [==============================] - 0s 428us/sample - loss: 0.5361 - acc: 0.8750 - val_loss: 0.6973 - val_acc: 0.5500\n",
            "Epoch 138/300\n",
            "40/40 [==============================] - 0s 407us/sample - loss: 0.5067 - acc: 0.8500 - val_loss: 0.6981 - val_acc: 0.5500\n",
            "Epoch 139/300\n",
            "40/40 [==============================] - 0s 414us/sample - loss: 0.5172 - acc: 0.8750 - val_loss: 0.6991 - val_acc: 0.5500\n",
            "Epoch 140/300\n",
            "40/40 [==============================] - 0s 477us/sample - loss: 0.5229 - acc: 0.8500 - val_loss: 0.7002 - val_acc: 0.5500\n",
            "Epoch 141/300\n",
            "40/40 [==============================] - 0s 406us/sample - loss: 0.4963 - acc: 0.9500 - val_loss: 0.7011 - val_acc: 0.5500\n",
            "Epoch 142/300\n",
            "40/40 [==============================] - 0s 448us/sample - loss: 0.4961 - acc: 0.9250 - val_loss: 0.7015 - val_acc: 0.5500\n",
            "Epoch 143/300\n",
            "40/40 [==============================] - 0s 466us/sample - loss: 0.5196 - acc: 0.8250 - val_loss: 0.7013 - val_acc: 0.5500\n",
            "Epoch 144/300\n",
            "40/40 [==============================] - 0s 426us/sample - loss: 0.5323 - acc: 0.8500 - val_loss: 0.7004 - val_acc: 0.5500\n",
            "Epoch 145/300\n",
            "40/40 [==============================] - 0s 475us/sample - loss: 0.5196 - acc: 0.8500 - val_loss: 0.6995 - val_acc: 0.5500\n",
            "Epoch 146/300\n",
            "40/40 [==============================] - 0s 429us/sample - loss: 0.5240 - acc: 0.8500 - val_loss: 0.6990 - val_acc: 0.5500\n",
            "Epoch 147/300\n",
            "40/40 [==============================] - 0s 437us/sample - loss: 0.4903 - acc: 0.9250 - val_loss: 0.6991 - val_acc: 0.5500\n",
            "Epoch 148/300\n",
            "40/40 [==============================] - 0s 402us/sample - loss: 0.5045 - acc: 0.8500 - val_loss: 0.6996 - val_acc: 0.5500\n",
            "Epoch 149/300\n",
            "40/40 [==============================] - 0s 595us/sample - loss: 0.5072 - acc: 0.8750 - val_loss: 0.7006 - val_acc: 0.5500\n",
            "Epoch 150/300\n",
            "40/40 [==============================] - 0s 540us/sample - loss: 0.5019 - acc: 0.9000 - val_loss: 0.7017 - val_acc: 0.5500\n",
            "Epoch 151/300\n",
            "40/40 [==============================] - 0s 464us/sample - loss: 0.4961 - acc: 0.9000 - val_loss: 0.7025 - val_acc: 0.5500\n",
            "Epoch 152/300\n",
            "40/40 [==============================] - 0s 398us/sample - loss: 0.5083 - acc: 0.8750 - val_loss: 0.7026 - val_acc: 0.5500\n",
            "Epoch 153/300\n",
            "40/40 [==============================] - 0s 424us/sample - loss: 0.4885 - acc: 0.9000 - val_loss: 0.7023 - val_acc: 0.5500\n",
            "Epoch 154/300\n",
            "40/40 [==============================] - 0s 530us/sample - loss: 0.4856 - acc: 0.9000 - val_loss: 0.7018 - val_acc: 0.5500\n",
            "Epoch 155/300\n",
            "40/40 [==============================] - 0s 412us/sample - loss: 0.5035 - acc: 0.9000 - val_loss: 0.7012 - val_acc: 0.5500\n",
            "Epoch 156/300\n",
            "40/40 [==============================] - 0s 491us/sample - loss: 0.4737 - acc: 0.9000 - val_loss: 0.7009 - val_acc: 0.5500\n",
            "Epoch 157/300\n",
            "40/40 [==============================] - 0s 444us/sample - loss: 0.4827 - acc: 0.9250 - val_loss: 0.7009 - val_acc: 0.5500\n",
            "Epoch 158/300\n",
            "40/40 [==============================] - 0s 442us/sample - loss: 0.4847 - acc: 0.9000 - val_loss: 0.7010 - val_acc: 0.5500\n",
            "Epoch 159/300\n",
            "40/40 [==============================] - 0s 442us/sample - loss: 0.4771 - acc: 0.9250 - val_loss: 0.7018 - val_acc: 0.5500\n",
            "Epoch 160/300\n",
            "40/40 [==============================] - 0s 442us/sample - loss: 0.4827 - acc: 0.9250 - val_loss: 0.7028 - val_acc: 0.5500\n",
            "Epoch 161/300\n",
            "40/40 [==============================] - 0s 476us/sample - loss: 0.4655 - acc: 0.9750 - val_loss: 0.7038 - val_acc: 0.5500\n",
            "Epoch 162/300\n",
            "40/40 [==============================] - 0s 434us/sample - loss: 0.4946 - acc: 0.9000 - val_loss: 0.7044 - val_acc: 0.5500\n",
            "Epoch 163/300\n",
            "40/40 [==============================] - 0s 452us/sample - loss: 0.4740 - acc: 0.9250 - val_loss: 0.7045 - val_acc: 0.5500\n",
            "Epoch 164/300\n",
            "40/40 [==============================] - 0s 414us/sample - loss: 0.5010 - acc: 0.8500 - val_loss: 0.7043 - val_acc: 0.5500\n",
            "Epoch 165/300\n",
            "40/40 [==============================] - 0s 434us/sample - loss: 0.4914 - acc: 0.9000 - val_loss: 0.7039 - val_acc: 0.5500\n",
            "Epoch 166/300\n",
            "40/40 [==============================] - 0s 463us/sample - loss: 0.4803 - acc: 0.8500 - val_loss: 0.7034 - val_acc: 0.5500\n",
            "Epoch 167/300\n",
            "40/40 [==============================] - 0s 414us/sample - loss: 0.4491 - acc: 0.9250 - val_loss: 0.7031 - val_acc: 0.5500\n",
            "Epoch 168/300\n",
            "40/40 [==============================] - 0s 432us/sample - loss: 0.4763 - acc: 0.9000 - val_loss: 0.7034 - val_acc: 0.5500\n",
            "Epoch 169/300\n",
            "40/40 [==============================] - 0s 475us/sample - loss: 0.4808 - acc: 0.9000 - val_loss: 0.7039 - val_acc: 0.5500\n",
            "Epoch 170/300\n",
            "40/40 [==============================] - 0s 501us/sample - loss: 0.4984 - acc: 0.8000 - val_loss: 0.7041 - val_acc: 0.5500\n",
            "Epoch 171/300\n",
            "40/40 [==============================] - 0s 464us/sample - loss: 0.5096 - acc: 0.8500 - val_loss: 0.7044 - val_acc: 0.5500\n",
            "Epoch 172/300\n",
            "40/40 [==============================] - 0s 408us/sample - loss: 0.4667 - acc: 0.9000 - val_loss: 0.7048 - val_acc: 0.5500\n",
            "Epoch 173/300\n",
            "40/40 [==============================] - 0s 401us/sample - loss: 0.4701 - acc: 0.9000 - val_loss: 0.7053 - val_acc: 0.5500\n",
            "Epoch 174/300\n",
            "40/40 [==============================] - 0s 409us/sample - loss: 0.4806 - acc: 0.8250 - val_loss: 0.7058 - val_acc: 0.5500\n",
            "Epoch 175/300\n",
            "40/40 [==============================] - 0s 466us/sample - loss: 0.4778 - acc: 0.9500 - val_loss: 0.7063 - val_acc: 0.5500\n",
            "Epoch 176/300\n",
            "40/40 [==============================] - 0s 447us/sample - loss: 0.4785 - acc: 0.9000 - val_loss: 0.7065 - val_acc: 0.5500\n",
            "Epoch 177/300\n",
            "40/40 [==============================] - 0s 490us/sample - loss: 0.4912 - acc: 0.9000 - val_loss: 0.7063 - val_acc: 0.5500\n",
            "Epoch 178/300\n",
            "40/40 [==============================] - 0s 530us/sample - loss: 0.4629 - acc: 0.9250 - val_loss: 0.7062 - val_acc: 0.5500\n",
            "Epoch 179/300\n",
            "40/40 [==============================] - 0s 513us/sample - loss: 0.4697 - acc: 0.9000 - val_loss: 0.7061 - val_acc: 0.5500\n",
            "Epoch 180/300\n",
            "40/40 [==============================] - 0s 487us/sample - loss: 0.4704 - acc: 0.8500 - val_loss: 0.7059 - val_acc: 0.5500\n",
            "Epoch 181/300\n",
            "40/40 [==============================] - 0s 457us/sample - loss: 0.4739 - acc: 0.9000 - val_loss: 0.7057 - val_acc: 0.5500\n",
            "Epoch 182/300\n",
            "40/40 [==============================] - 0s 435us/sample - loss: 0.4758 - acc: 0.8500 - val_loss: 0.7057 - val_acc: 0.5500\n",
            "Epoch 183/300\n",
            "40/40 [==============================] - 0s 449us/sample - loss: 0.4772 - acc: 0.9250 - val_loss: 0.7060 - val_acc: 0.5500\n",
            "Epoch 184/300\n",
            "40/40 [==============================] - 0s 431us/sample - loss: 0.4732 - acc: 0.9000 - val_loss: 0.7066 - val_acc: 0.5500\n",
            "Epoch 185/300\n",
            "40/40 [==============================] - 0s 457us/sample - loss: 0.4649 - acc: 0.9250 - val_loss: 0.7072 - val_acc: 0.5500\n",
            "Epoch 186/300\n",
            "40/40 [==============================] - 0s 519us/sample - loss: 0.4663 - acc: 0.8500 - val_loss: 0.7077 - val_acc: 0.5500\n",
            "Epoch 187/300\n",
            "40/40 [==============================] - 0s 445us/sample - loss: 0.4566 - acc: 0.9250 - val_loss: 0.7080 - val_acc: 0.5500\n",
            "Epoch 188/300\n",
            "40/40 [==============================] - 0s 490us/sample - loss: 0.4761 - acc: 0.8500 - val_loss: 0.7079 - val_acc: 0.5500\n",
            "Epoch 189/300\n",
            "40/40 [==============================] - 0s 441us/sample - loss: 0.4706 - acc: 0.8750 - val_loss: 0.7077 - val_acc: 0.5500\n",
            "Epoch 190/300\n",
            "40/40 [==============================] - 0s 415us/sample - loss: 0.4594 - acc: 0.9000 - val_loss: 0.7074 - val_acc: 0.5500\n",
            "Epoch 191/300\n",
            "40/40 [==============================] - 0s 471us/sample - loss: 0.4468 - acc: 0.9250 - val_loss: 0.7071 - val_acc: 0.5500\n",
            "Epoch 192/300\n",
            "40/40 [==============================] - 0s 598us/sample - loss: 0.4687 - acc: 0.8750 - val_loss: 0.7072 - val_acc: 0.5500\n",
            "Epoch 193/300\n",
            "40/40 [==============================] - 0s 527us/sample - loss: 0.4893 - acc: 0.8750 - val_loss: 0.7075 - val_acc: 0.5500\n",
            "Epoch 194/300\n",
            "40/40 [==============================] - 0s 466us/sample - loss: 0.4441 - acc: 0.9500 - val_loss: 0.7080 - val_acc: 0.5500\n",
            "Epoch 195/300\n",
            "40/40 [==============================] - 0s 478us/sample - loss: 0.4740 - acc: 0.8250 - val_loss: 0.7084 - val_acc: 0.5500\n",
            "Epoch 196/300\n",
            "40/40 [==============================] - 0s 420us/sample - loss: 0.4583 - acc: 0.9000 - val_loss: 0.7087 - val_acc: 0.5500\n",
            "Epoch 197/300\n",
            "40/40 [==============================] - 0s 518us/sample - loss: 0.4720 - acc: 0.9000 - val_loss: 0.7090 - val_acc: 0.5500\n",
            "Epoch 198/300\n",
            "40/40 [==============================] - 0s 479us/sample - loss: 0.4714 - acc: 0.9000 - val_loss: 0.7092 - val_acc: 0.5500\n",
            "Epoch 199/300\n",
            "40/40 [==============================] - 0s 453us/sample - loss: 0.5096 - acc: 0.8000 - val_loss: 0.7092 - val_acc: 0.5500\n",
            "Epoch 200/300\n",
            "40/40 [==============================] - 0s 491us/sample - loss: 0.4723 - acc: 0.8250 - val_loss: 0.7092 - val_acc: 0.5500\n",
            "Epoch 201/300\n",
            "40/40 [==============================] - 0s 512us/sample - loss: 0.4638 - acc: 0.8500 - val_loss: 0.7093 - val_acc: 0.5500\n",
            "Epoch 202/300\n",
            "40/40 [==============================] - 0s 469us/sample - loss: 0.4784 - acc: 0.8250 - val_loss: 0.7092 - val_acc: 0.5500\n",
            "Epoch 203/300\n",
            "40/40 [==============================] - 0s 531us/sample - loss: 0.4613 - acc: 0.9000 - val_loss: 0.7092 - val_acc: 0.5500\n",
            "Epoch 204/300\n",
            "40/40 [==============================] - 0s 448us/sample - loss: 0.4607 - acc: 0.9000 - val_loss: 0.7093 - val_acc: 0.5500\n",
            "Epoch 205/300\n",
            "40/40 [==============================] - 0s 420us/sample - loss: 0.4601 - acc: 0.9000 - val_loss: 0.7095 - val_acc: 0.5500\n",
            "Epoch 206/300\n",
            "40/40 [==============================] - 0s 417us/sample - loss: 0.4756 - acc: 0.8500 - val_loss: 0.7097 - val_acc: 0.5500\n",
            "Epoch 207/300\n",
            "40/40 [==============================] - 0s 533us/sample - loss: 0.4891 - acc: 0.8750 - val_loss: 0.7099 - val_acc: 0.5500\n",
            "Epoch 208/300\n",
            "40/40 [==============================] - 0s 427us/sample - loss: 0.4497 - acc: 0.9000 - val_loss: 0.7103 - val_acc: 0.5500\n",
            "Epoch 209/300\n",
            "40/40 [==============================] - 0s 413us/sample - loss: 0.4504 - acc: 0.9000 - val_loss: 0.7107 - val_acc: 0.5500\n",
            "Epoch 210/300\n",
            "40/40 [==============================] - 0s 464us/sample - loss: 0.4963 - acc: 0.8250 - val_loss: 0.7110 - val_acc: 0.5500\n",
            "Epoch 211/300\n",
            "40/40 [==============================] - 0s 439us/sample - loss: 0.4566 - acc: 0.9000 - val_loss: 0.7113 - val_acc: 0.5500\n",
            "Epoch 212/300\n",
            "40/40 [==============================] - 0s 480us/sample - loss: 0.4730 - acc: 0.8250 - val_loss: 0.7112 - val_acc: 0.5500\n",
            "Epoch 213/300\n",
            "40/40 [==============================] - 0s 427us/sample - loss: 0.5180 - acc: 0.8000 - val_loss: 0.7109 - val_acc: 0.5500\n",
            "Epoch 214/300\n",
            "40/40 [==============================] - 0s 392us/sample - loss: 0.4468 - acc: 0.9250 - val_loss: 0.7108 - val_acc: 0.5500\n",
            "Epoch 215/300\n",
            "40/40 [==============================] - 0s 408us/sample - loss: 0.4647 - acc: 0.9000 - val_loss: 0.7110 - val_acc: 0.5500\n",
            "Epoch 216/300\n",
            "40/40 [==============================] - 0s 420us/sample - loss: 0.4615 - acc: 0.8500 - val_loss: 0.7114 - val_acc: 0.5500\n",
            "Epoch 217/300\n",
            "40/40 [==============================] - 0s 431us/sample - loss: 0.4342 - acc: 0.8750 - val_loss: 0.7120 - val_acc: 0.5500\n",
            "Epoch 218/300\n",
            "40/40 [==============================] - 0s 464us/sample - loss: 0.4596 - acc: 0.9250 - val_loss: 0.7124 - val_acc: 0.5500\n",
            "Epoch 219/300\n",
            "40/40 [==============================] - 0s 418us/sample - loss: 0.4322 - acc: 0.9000 - val_loss: 0.7131 - val_acc: 0.5500\n",
            "Epoch 220/300\n",
            "40/40 [==============================] - 0s 416us/sample - loss: 0.4517 - acc: 0.8500 - val_loss: 0.7136 - val_acc: 0.5500\n",
            "Epoch 221/300\n",
            "40/40 [==============================] - 0s 501us/sample - loss: 0.4192 - acc: 0.9500 - val_loss: 0.7140 - val_acc: 0.5500\n",
            "Epoch 222/300\n",
            "40/40 [==============================] - 0s 454us/sample - loss: 0.4657 - acc: 0.9000 - val_loss: 0.7146 - val_acc: 0.5500\n",
            "Epoch 223/300\n",
            "40/40 [==============================] - 0s 475us/sample - loss: 0.4576 - acc: 0.9000 - val_loss: 0.7146 - val_acc: 0.5500\n",
            "Epoch 224/300\n",
            "40/40 [==============================] - 0s 424us/sample - loss: 0.4494 - acc: 0.9000 - val_loss: 0.7142 - val_acc: 0.5500\n",
            "Epoch 225/300\n",
            "40/40 [==============================] - 0s 426us/sample - loss: 0.4327 - acc: 0.9250 - val_loss: 0.7138 - val_acc: 0.5500\n",
            "Epoch 226/300\n",
            "40/40 [==============================] - 0s 425us/sample - loss: 0.4659 - acc: 0.8250 - val_loss: 0.7133 - val_acc: 0.5500\n",
            "Epoch 227/300\n",
            "40/40 [==============================] - 0s 499us/sample - loss: 0.4661 - acc: 0.8000 - val_loss: 0.7130 - val_acc: 0.5500\n",
            "Epoch 228/300\n",
            "40/40 [==============================] - 0s 413us/sample - loss: 0.4479 - acc: 0.8750 - val_loss: 0.7129 - val_acc: 0.5500\n",
            "Epoch 229/300\n",
            "40/40 [==============================] - 0s 419us/sample - loss: 0.4522 - acc: 0.8500 - val_loss: 0.7130 - val_acc: 0.5500\n",
            "Epoch 230/300\n",
            "40/40 [==============================] - 0s 498us/sample - loss: 0.4801 - acc: 0.8000 - val_loss: 0.7134 - val_acc: 0.5500\n",
            "Epoch 231/300\n",
            "40/40 [==============================] - 0s 447us/sample - loss: 0.4626 - acc: 0.8500 - val_loss: 0.7136 - val_acc: 0.5500\n",
            "Epoch 232/300\n",
            "40/40 [==============================] - 0s 430us/sample - loss: 0.4366 - acc: 0.8750 - val_loss: 0.7139 - val_acc: 0.5500\n",
            "Epoch 233/300\n",
            "40/40 [==============================] - 0s 475us/sample - loss: 0.4203 - acc: 0.9250 - val_loss: 0.7144 - val_acc: 0.5500\n",
            "Epoch 234/300\n",
            "40/40 [==============================] - 0s 474us/sample - loss: 0.4268 - acc: 0.9500 - val_loss: 0.7154 - val_acc: 0.5500\n",
            "Epoch 235/300\n",
            "40/40 [==============================] - 0s 585us/sample - loss: 0.4706 - acc: 0.7750 - val_loss: 0.7161 - val_acc: 0.5500\n",
            "Epoch 236/300\n",
            "40/40 [==============================] - 0s 435us/sample - loss: 0.4455 - acc: 0.9500 - val_loss: 0.7166 - val_acc: 0.5500\n",
            "Epoch 237/300\n",
            "40/40 [==============================] - 0s 526us/sample - loss: 0.4259 - acc: 0.9250 - val_loss: 0.7167 - val_acc: 0.5500\n",
            "Epoch 238/300\n",
            "40/40 [==============================] - 0s 392us/sample - loss: 0.4770 - acc: 0.7750 - val_loss: 0.7165 - val_acc: 0.5500\n",
            "Epoch 239/300\n",
            "40/40 [==============================] - 0s 499us/sample - loss: 0.4572 - acc: 0.8500 - val_loss: 0.7164 - val_acc: 0.5500\n",
            "Epoch 240/300\n",
            "40/40 [==============================] - 0s 442us/sample - loss: 0.4568 - acc: 0.8500 - val_loss: 0.7162 - val_acc: 0.5500\n",
            "Epoch 241/300\n",
            "40/40 [==============================] - 0s 472us/sample - loss: 0.4196 - acc: 0.9250 - val_loss: 0.7159 - val_acc: 0.5500\n",
            "Epoch 242/300\n",
            "40/40 [==============================] - 0s 480us/sample - loss: 0.4739 - acc: 0.8250 - val_loss: 0.7157 - val_acc: 0.5500\n",
            "Epoch 243/300\n",
            "40/40 [==============================] - 0s 414us/sample - loss: 0.4400 - acc: 0.8750 - val_loss: 0.7156 - val_acc: 0.5500\n",
            "Epoch 244/300\n",
            "40/40 [==============================] - 0s 456us/sample - loss: 0.4246 - acc: 0.9750 - val_loss: 0.7160 - val_acc: 0.5500\n",
            "Epoch 245/300\n",
            "40/40 [==============================] - 0s 462us/sample - loss: 0.4376 - acc: 0.9250 - val_loss: 0.7164 - val_acc: 0.5500\n",
            "Epoch 246/300\n",
            "40/40 [==============================] - 0s 420us/sample - loss: 0.4080 - acc: 0.9500 - val_loss: 0.7171 - val_acc: 0.5500\n",
            "Epoch 247/300\n",
            "40/40 [==============================] - 0s 433us/sample - loss: 0.4379 - acc: 0.8750 - val_loss: 0.7176 - val_acc: 0.5500\n",
            "Epoch 248/300\n",
            "40/40 [==============================] - 0s 448us/sample - loss: 0.4156 - acc: 0.9250 - val_loss: 0.7181 - val_acc: 0.5500\n",
            "Epoch 249/300\n",
            "40/40 [==============================] - 0s 467us/sample - loss: 0.4333 - acc: 0.8500 - val_loss: 0.7183 - val_acc: 0.5500\n",
            "Epoch 250/300\n",
            "40/40 [==============================] - 0s 421us/sample - loss: 0.4056 - acc: 0.9500 - val_loss: 0.7183 - val_acc: 0.5500\n",
            "Epoch 251/300\n",
            "40/40 [==============================] - 0s 606us/sample - loss: 0.4589 - acc: 0.8750 - val_loss: 0.7183 - val_acc: 0.5500\n",
            "Epoch 252/300\n",
            "40/40 [==============================] - 0s 473us/sample - loss: 0.4250 - acc: 0.9000 - val_loss: 0.7181 - val_acc: 0.5500\n",
            "Epoch 253/300\n",
            "40/40 [==============================] - 0s 486us/sample - loss: 0.4519 - acc: 0.8500 - val_loss: 0.7181 - val_acc: 0.5500\n",
            "Epoch 254/300\n",
            "40/40 [==============================] - 0s 466us/sample - loss: 0.4753 - acc: 0.8250 - val_loss: 0.7184 - val_acc: 0.5500\n",
            "Epoch 255/300\n",
            "40/40 [==============================] - 0s 409us/sample - loss: 0.4591 - acc: 0.8000 - val_loss: 0.7187 - val_acc: 0.5500\n",
            "Epoch 256/300\n",
            "40/40 [==============================] - 0s 475us/sample - loss: 0.3975 - acc: 0.9750 - val_loss: 0.7191 - val_acc: 0.5500\n",
            "Epoch 257/300\n",
            "40/40 [==============================] - 0s 395us/sample - loss: 0.4403 - acc: 0.9000 - val_loss: 0.7195 - val_acc: 0.5500\n",
            "Epoch 258/300\n",
            "40/40 [==============================] - 0s 430us/sample - loss: 0.4143 - acc: 0.9250 - val_loss: 0.7201 - val_acc: 0.5500\n",
            "Epoch 259/300\n",
            "40/40 [==============================] - 0s 422us/sample - loss: 0.4303 - acc: 0.9250 - val_loss: 0.7206 - val_acc: 0.5500\n",
            "Epoch 260/300\n",
            "40/40 [==============================] - 0s 481us/sample - loss: 0.4637 - acc: 0.9000 - val_loss: 0.7212 - val_acc: 0.5500\n",
            "Epoch 261/300\n",
            "40/40 [==============================] - 0s 448us/sample - loss: 0.4474 - acc: 0.8750 - val_loss: 0.7217 - val_acc: 0.5500\n",
            "Epoch 262/300\n",
            "40/40 [==============================] - 0s 481us/sample - loss: 0.4085 - acc: 0.9000 - val_loss: 0.7219 - val_acc: 0.5500\n",
            "Epoch 263/300\n",
            "40/40 [==============================] - 0s 573us/sample - loss: 0.4025 - acc: 0.9500 - val_loss: 0.7219 - val_acc: 0.5500\n",
            "Epoch 264/300\n",
            "40/40 [==============================] - 0s 390us/sample - loss: 0.4559 - acc: 0.8250 - val_loss: 0.7218 - val_acc: 0.5500\n",
            "Epoch 265/300\n",
            "40/40 [==============================] - 0s 424us/sample - loss: 0.4114 - acc: 0.9000 - val_loss: 0.7214 - val_acc: 0.5500\n",
            "Epoch 266/300\n",
            "40/40 [==============================] - 0s 453us/sample - loss: 0.4642 - acc: 0.8000 - val_loss: 0.7212 - val_acc: 0.5500\n",
            "Epoch 267/300\n",
            "40/40 [==============================] - 0s 412us/sample - loss: 0.4179 - acc: 0.9250 - val_loss: 0.7212 - val_acc: 0.5500\n",
            "Epoch 268/300\n",
            "40/40 [==============================] - 0s 435us/sample - loss: 0.4190 - acc: 0.8750 - val_loss: 0.7215 - val_acc: 0.5500\n",
            "Epoch 269/300\n",
            "40/40 [==============================] - 0s 403us/sample - loss: 0.4545 - acc: 0.8750 - val_loss: 0.7221 - val_acc: 0.5500\n",
            "Epoch 270/300\n",
            "40/40 [==============================] - 0s 403us/sample - loss: 0.4071 - acc: 0.9500 - val_loss: 0.7228 - val_acc: 0.5500\n",
            "Epoch 271/300\n",
            "40/40 [==============================] - 0s 450us/sample - loss: 0.4263 - acc: 0.8250 - val_loss: 0.7235 - val_acc: 0.5500\n",
            "Epoch 272/300\n",
            "40/40 [==============================] - 0s 506us/sample - loss: 0.4511 - acc: 0.8250 - val_loss: 0.7240 - val_acc: 0.5500\n",
            "Epoch 273/300\n",
            "40/40 [==============================] - 0s 594us/sample - loss: 0.4224 - acc: 0.9500 - val_loss: 0.7246 - val_acc: 0.5500\n",
            "Epoch 274/300\n",
            "40/40 [==============================] - 0s 468us/sample - loss: 0.4415 - acc: 0.8750 - val_loss: 0.7250 - val_acc: 0.5500\n",
            "Epoch 275/300\n",
            "40/40 [==============================] - 0s 605us/sample - loss: 0.4545 - acc: 0.8000 - val_loss: 0.7249 - val_acc: 0.5500\n",
            "Epoch 276/300\n",
            "40/40 [==============================] - 0s 539us/sample - loss: 0.4415 - acc: 0.8500 - val_loss: 0.7246 - val_acc: 0.5500\n",
            "Epoch 277/300\n",
            "40/40 [==============================] - 0s 421us/sample - loss: 0.3857 - acc: 0.9750 - val_loss: 0.7243 - val_acc: 0.5500\n",
            "Epoch 278/300\n",
            "40/40 [==============================] - 0s 399us/sample - loss: 0.4482 - acc: 0.8750 - val_loss: 0.7239 - val_acc: 0.5500\n",
            "Epoch 279/300\n",
            "40/40 [==============================] - 0s 468us/sample - loss: 0.4223 - acc: 0.8750 - val_loss: 0.7238 - val_acc: 0.5500\n",
            "Epoch 280/300\n",
            "40/40 [==============================] - 0s 481us/sample - loss: 0.4465 - acc: 0.9000 - val_loss: 0.7241 - val_acc: 0.5500\n",
            "Epoch 281/300\n",
            "40/40 [==============================] - 0s 458us/sample - loss: 0.4110 - acc: 0.9250 - val_loss: 0.7248 - val_acc: 0.5500\n",
            "Epoch 282/300\n",
            "40/40 [==============================] - 0s 465us/sample - loss: 0.4484 - acc: 0.8250 - val_loss: 0.7256 - val_acc: 0.5500\n",
            "Epoch 283/300\n",
            "40/40 [==============================] - 0s 439us/sample - loss: 0.4119 - acc: 0.8750 - val_loss: 0.7263 - val_acc: 0.5500\n",
            "Epoch 284/300\n",
            "40/40 [==============================] - 0s 512us/sample - loss: 0.4353 - acc: 0.9250 - val_loss: 0.7270 - val_acc: 0.5500\n",
            "Epoch 285/300\n",
            "40/40 [==============================] - 0s 437us/sample - loss: 0.4367 - acc: 0.8750 - val_loss: 0.7277 - val_acc: 0.5500\n",
            "Epoch 286/300\n",
            "40/40 [==============================] - 0s 468us/sample - loss: 0.4143 - acc: 0.8750 - val_loss: 0.7281 - val_acc: 0.5500\n",
            "Epoch 287/300\n",
            "40/40 [==============================] - 0s 439us/sample - loss: 0.4550 - acc: 0.8250 - val_loss: 0.7284 - val_acc: 0.5500\n",
            "Epoch 288/300\n",
            "40/40 [==============================] - 0s 451us/sample - loss: 0.4259 - acc: 0.9000 - val_loss: 0.7284 - val_acc: 0.5500\n",
            "Epoch 289/300\n",
            "40/40 [==============================] - 0s 460us/sample - loss: 0.4792 - acc: 0.8500 - val_loss: 0.7282 - val_acc: 0.5500\n",
            "Epoch 290/300\n",
            "40/40 [==============================] - 0s 410us/sample - loss: 0.4722 - acc: 0.8000 - val_loss: 0.7280 - val_acc: 0.5500\n",
            "Epoch 291/300\n",
            "40/40 [==============================] - 0s 450us/sample - loss: 0.4439 - acc: 0.8500 - val_loss: 0.7277 - val_acc: 0.5500\n",
            "Epoch 292/300\n",
            "40/40 [==============================] - 0s 413us/sample - loss: 0.4379 - acc: 0.7750 - val_loss: 0.7272 - val_acc: 0.5500\n",
            "Epoch 293/300\n",
            "40/40 [==============================] - 0s 429us/sample - loss: 0.4248 - acc: 0.8750 - val_loss: 0.7268 - val_acc: 0.5500\n",
            "Epoch 294/300\n",
            "40/40 [==============================] - 0s 407us/sample - loss: 0.4602 - acc: 0.8500 - val_loss: 0.7265 - val_acc: 0.5500\n",
            "Epoch 295/300\n",
            "40/40 [==============================] - 0s 489us/sample - loss: 0.4608 - acc: 0.8250 - val_loss: 0.7265 - val_acc: 0.5500\n",
            "Epoch 296/300\n",
            "40/40 [==============================] - 0s 460us/sample - loss: 0.4323 - acc: 0.8750 - val_loss: 0.7266 - val_acc: 0.5500\n",
            "Epoch 297/300\n",
            "40/40 [==============================] - 0s 462us/sample - loss: 0.4534 - acc: 0.7750 - val_loss: 0.7271 - val_acc: 0.5500\n",
            "Epoch 298/300\n",
            "40/40 [==============================] - 0s 517us/sample - loss: 0.4695 - acc: 0.8000 - val_loss: 0.7280 - val_acc: 0.5500\n",
            "Epoch 299/300\n",
            "40/40 [==============================] - 0s 470us/sample - loss: 0.4163 - acc: 0.9000 - val_loss: 0.7288 - val_acc: 0.5500\n",
            "Epoch 300/300\n",
            "40/40 [==============================] - 0s 511us/sample - loss: 0.3845 - acc: 0.9000 - val_loss: 0.7295 - val_acc: 0.5500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zycv5hktVuzM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
